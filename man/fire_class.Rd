% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/fire_classification.R
\name{fire_class}
\alias{fire_class}
\title{Fit a FIRE Model for Classification}
\usage{
fire_class(
  X,
  Y,
  dat_T,
  kernels,
  kernels_params,
  kernel_iprior = "cfbm",
  iprior_param = NULL,
  kernel_class = "centred identity",
  class.labels,
  control
)
}
\arguments{
\item{X}{A numeric input in \code{array} or \code{list}}

\item{Y}{A categorical response vector}

\item{dat_T}{List of index sets for each mode}

\item{kernels}{List of kernel functions for each mode (see \code{\link{kernels_fire}})}

\item{kernels_params}{List of parameters for each kernel}

\item{kernel_iprior}{Type of I-prior kernel}

\item{iprior_param}{Parameter for I-prior kernel:
\itemize{
  \item \code{"cfbm"} - Hurst coefficient (default 0.5)
  \item \code{"rbf"} - lengthscale (default 1)
  \item \code{"linear"} - offset (default 0)
  \item \code{"poly"} - degree and offset (default c(2, mean(Y)))
}}

\item{kernel_class}{Class kernel. Either \code{"identity"}, \code{"centred identity"},
or a user-supplied positive semi-definite \eqn{c \times c} matrix.}

\item{class.labels}{Vector of distinct class labels (length \eqn{c}).}

\item{control}{A list of control parameters (see Details)}
}
\value{
An \code{fire_class} object. The \code{print()} and \code{summary()} methods display the model information.
}
\description{
Estimates a functional classification model using I-priors with Reproducing Kernel Hilbert Space (RKHS) norm.
The FIRE model parameters are estimated using an EM algorithm.
}
\details{
The \code{control} argument can include the following parameters:
\itemize{
  \item{\code{scale}: Logical indicating whether to center the response (default TRUE)}
  \item{\code{maxiter}: Maximum number of EM iterations (default 200)}
  \item{\code{stop.eps}: Convergence tolerance (default 1e-3)}
  \item{\code{constant_g}: Logical indicating whether to include constant kernel term in g (default TRUE)}
  \item{\code{constant_h}: Logical indicating whether to include constant kernel term in h (default FALSE)}
  \item{\code{center}: Logical indicating whether to center the kernel g (default FALSE)}
  \item{\code{std}: Logical indicating whether to standardise the kernel g (default TRUE)}
  \item{\code{par_init}: Optional list of initial parameter values (lambda, noise)}
  \item{\code{os_type}: Operating system type for compatibility ("Apple" or "Windows", default "Apple")}
  \item{\code{cores}: Number of cores for parallel computation (default: detectCores() - 1)}
  \item{\code{asymptote}: Logical to use asymptotic initial values (default TRUE)}
  \item{\code{sample_id}: Which mode contains samples (default 1)}
  \item{\code{epsilon}: Small positive constant in initialisation of EM algorithm (default 1)}
}
}
\examples{
set.seed(42)
n_train <- 5; n_test  <- 2; n <- n_train + n_test
MatA <- matrix(c(1,1,1,0,0,0,0,0,0), nrow = 3, byrow = TRUE)
MatB <- matrix(c(0,0,0,0,0,0,1,1,1), nrow = 3, byrow = TRUE)
Y <- factor(c("A","A","B","B","A","A","B"), levels = c("A","B"))
# Generate matrices with small Gaussian noise
X <- lapply(seq_len(n), function(i) {base <- if (Y[i] == "A") MatA else MatB
noise <- matrix(rnorm(9, sd = 0.15), nrow = 3)
base + noise })

# Train/test split: first 5 train, last 2 test
X_train <- X[1:n_train]; X_test  <- X[(n_train + 1):n]
Y_train <- Y[1:n_train]; Y_test  <- Y[(n_train + 1):n]

dat_T <- list(1:3, 1:3)
mod <- fire_class(X = X_train, Y = Y_train, dat_T = dat_T,
 kernels = list(cfbm, cfbm), kernels_params = list(0.5, 0.5),
 class.labels = levels(Y_train), control = list(maxiter = 20, stop.eps = 1e-3))

}
\seealso{
\code{\link{kernels_fire}}, \code{\link{utils_classification}}
}
